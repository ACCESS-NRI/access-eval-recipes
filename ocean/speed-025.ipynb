{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb84e7f4-7626-44a1-8bd6-97c397975bdd",
   "metadata": {},
   "source": [
    "# Plot frames for ACCESS-OM3 surface speed movie\n",
    "\n",
    "https://github.com/COSIMA/cosima-recipes/blob/main/Tutorials/Model_Agnostic_Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b496fe34-0709-4eb8-ab03-cefe4a7421da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import intake\n",
    "import dask\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import cf_xarray as cfxr\n",
    "import pint_xarray\n",
    "from pint import application_registry as ureg\n",
    "import cf_xarray.units\n",
    "import cftime\n",
    "import xgcm\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean as cm\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cft\n",
    "\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1958a5c5-1503-4547-a181-00bde2a54eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.set_options(keep_attrs=True); # cf_xarray works best when xarray keeps attributes by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392504fd-35a0-4027-b33a-ae0ecf158be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/COSIMA/cosima-recipes/blob/main/Tutorials/ACCESS-NRI_Intake_Catalog.ipynb\n",
    "# Try passing the following argument to your to_dask or to_dataset_dict call:\n",
    "# See the xarray documentation on Reading multi-file datasets for more details about these arguments.\n",
    "# https://docs.xarray.dev/en/stable/user-guide/io.html#reading-multi-file-datasets\n",
    "\n",
    "xarray_combine_by_coords_kwargs=dict(\n",
    "    compat=\"override\",\n",
    "    data_vars=\"minimal\",\n",
    "    coords=\"minimal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4077122-37c7-41ee-bf1a-a0ce7516fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f20d9-bdd5-4b40-9dca-d687500c6ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "thisdir = '/g/data/v45/aek156/notebooks/github/aekiss/access-eval-recipes/ocean/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51198acb-474c-49df-91e9-fbcdf05915da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH='/scratch/v45/aek156/access-om3/archive/MOM6-CICE6-1deg_jra55do_ryf.iss138/'\n",
    "# PATH='/scratch/v45/aek156/access-om3/archive/MOM6-CICE6-1deg_jra55do_ryf.testAug2024/'\n",
    "# datastore = intake.open_esm_datastore(PATH+'intake_datastore.json', columns_with_iterables=['variable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d8147-5a23-4c7f-b420-a3b51d25a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH='/g/data/tm70/ml0072/COMMON/git_repos/test-Reichl-2025-04-continue/archive/'\n",
    "#datastore = intake.open_esm_datastore(PATH+'intake_esm_ds.json', columns_with_iterables=['variable'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830d9f11-052d-4f54-8681-2773b8b23b13",
   "metadata": {},
   "source": [
    "https://access-nri.zulipchat.com/#narrow/dm/784080,784272-dm/near/523926733\n",
    "\n",
    "Everything is here\n",
    "/g/data/tm70/ml0072/COMMON/git_repos/control_runs/ctrl_25km_1st_version\n",
    "\n",
    "where\n",
    "\n",
    "dev-MC_025deg_jra_ryf_alpha_rel covers year 00-19\n",
    "\n",
    "test-Reichl-2025-04-continue covers 20-48\n",
    "\n",
    "ctrl_run_25km_0.5 currently covers 49-62. Ongoing data will be temporarily transferred here as well.\n",
    "\n",
    "dev-MC_025deg_jra_ryf_alpha_rel and test-Reichl-2025-04-continue share the same topo, but different MOM_parameters and different timesteps\n",
    "the topos are different from test-Reichl-2025-04-continue and ctrl_run_25km_0.5 but they share the same MOM_parameters\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e231d90-95f5-416c-b33b-3bf5e7008c2a",
   "metadata": {},
   "source": [
    "PATH = '/g/data/tm70/ml0072/COMMON/git_repos/control_runs/ctrl_25km_1st_version/'\n",
    "catalogs = [\n",
    "    PATH+'dev-MC_025deg_jra_ryf_alpha_rel/archive/intake_esm_ds.json',\n",
    "    PATH+'test-Reichl-2025-04-continue/archive/intake_esm_ds.json',\n",
    "    # PATH+'ctrl_run_25km_0.5/archive/intake_esm_ds.json', # faulty\n",
    "    'ctrl_run_25km_0.5_intake_esm_ds.json', # replacement for faulty one above\n",
    "    # '/g/data/v45/aek156/notebooks/github/aekiss/access-eval-recipes/ocean/ctrl_run_25km_0.5_intake_esm_ds.json', # replacement for faulty one above\n",
    "    # PATH+'ctrl_run_25km_0.5_2025.02.17_bathy/archive/intake_esm_ds.json',\n",
    "    # PATH+'ctrl_run_25km_0.5_tm70/archive/intake_esm_ds.json',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c7f0a3-e3af-4fba-90d7-47735b87d2be",
   "metadata": {},
   "source": [
    "https://access-nri.zulipchat.com/#narrow/dm/784080,784272-dm/near/524167154\n",
    "\n",
    "Minghang Li: Hi Andrew, I've finally managed to move the data to ik11 and just created an esm datastore for this. /g/data/ik11/outputs/access-om3-025/MC_25km_jra_ryf_0.5_prerelease I haven’t tested it yet, so please let me know if you notice anything unusual.\n",
    "\n",
    "Minghang Li: The most up-to-date year currently available is 1988. I’ll continue transferring data and updating the esm-datastore as new data become available.\n",
    "\n",
    "Minghang Li: It seems the newly generated ESM datastore might not be correctly configured. I’m reaching out to Charles to see if he can help diagnose the issue.\n",
    "\n",
    "Minghang Li: Hi Andrew, **We’re using different horizontal grids for the runs - years 0–48 use one version, while years 49 onward use a double precision version.** As a result, when generating the ESM datastore, I’m running into an error due to the differing grid definitions ValueError: Resulting object does not have monotonic global indexes along dimension yh. I can apply some postprocessing to standardise the grid across variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e8727c-8264-4781-84a7-ff95dd89b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/g/data/tm70/ml0072/COMMON/git_repos/control_runs/ctrl_25km_1st_version/'\n",
    "catalogs = [\n",
    "    # 'MC_25km_jra_ryf_0.5_prerelease_0-19.json',\n",
    "    # 'MC_25km_jra_ryf_0.5_prerelease_20-48.json',\n",
    "    'MC_25km_jra_ryf_0.5_prerelease_49-62.json', # different grid from here onwards\n",
    "    # PATH+'test-Reichl-2025-04-continue/archive/intake_esm_ds.json',\n",
    "    # PATH+'ctrl_run_25km_0.5/archive/intake_esm_ds.json', # faulty\n",
    "    # 'ctrl_run_25km_0.5_intake_esm_ds.json', # replacement for faulty one above\n",
    "    '/g/data/ik11/outputs/access-om3-025/MC_25km_jra_ryf_0.5_prerelease/63-ongoing/63-ongoing.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145df3e-f042-44f3-b1d0-63c16db6476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datastores = [ intake.open_esm_datastore(c, columns_with_iterables=['variable']) for c in catalogs ]\n",
    "# datastore = pd.concat(datastores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8908e138-7857-4d9b-b2c2-77e27a456eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datastores"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da3eb56c-5cd6-445a-9fa8-74fed7b48956",
   "metadata": {},
   "source": [
    "datastore.search(path=ncpath+'scalar.*',\n",
    "                 frequency='1day').df.head()['variable_cell_methods'][0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a816bd6b-a43d-4dd9-9315-55b77716c8ef",
   "metadata": {},
   "source": [
    "datastore.search(path=ncpath+'scalar.*',\n",
    "                 frequency='1day',\n",
    "                 variable_cell_methods='.*time: point.*')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e9e06ee-84b4-49c4-afe9-2ed5f1bf4e3f",
   "metadata": {},
   "source": [
    "datastore.search(path='.*access-om3\\.mom6\\.h\\.native.*',\n",
    "                 frequency='1mon').df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2adeed1f-9ac1-4acd-a7c3-be3812f766df",
   "metadata": {},
   "source": [
    "datastore.search(path='.*access-om3\\.mom6\\.h\\.native.*',\n",
    "                 frequency='1mon').df.head()['variable_cell_methods'][0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52eadf87-6baa-4422-ad3d-80c7981bd7f0",
   "metadata": {},
   "source": [
    "datastore.search(path='.*access-om3\\.mom6\\.h\\.native.*',\n",
    "                 frequency='1mon',\n",
    "                 variable_cell_methods='.*time: mean.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1da901b-97c9-4c96-83aa-3dda911dac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coords from short run without processor masking\n",
    "# https://github.com/aekiss/MOM6-CICE6/commit/59ed8ffc6ae1d4a79821a951924e7c853d9b788a\n",
    "# https://xgcm.readthedocs.io/en/latest/xgcm-examples/03_MOM6.html#A-note-on-geographical-coordinates\n",
    "static = xr.open_dataset('/g/data/ik11/outputs/access-om3-025/grid/access-om3.mom6.static.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9967e10-3152-44ae-8dbe-7603505f6ede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "static"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319336d-94a6-4d17-8f95-1def8837b07a",
   "metadata": {},
   "source": [
    "see https://xgcm.readthedocs.io/en/latest/xgcm-examples/03_MOM6.html#xgcm-grid-definition\n",
    "\n",
    "ACCESS-OM3 uses a non-symmetric memory layout, i.e. all fields have the same i and j sizes. See\n",
    "https://mom6.readthedocs.io/en/main/api/generated/pages/Horizontal_Indexing.html?highlight=symmetric#declaration-of-variables\n",
    "\n",
    "`MOM_parameter_doc.layout`:\n",
    "```\n",
    "!SYMMETRIC_MEMORY_ = False      !   [Boolean]\n",
    "                                ! If defined, the velocity point data domain includes every face of the\n",
    "                                ! thickness points. In other words, some arrays are larger than others,\n",
    "                                ! depending on where they are on the staggered grid.  Also, the starting index\n",
    "                                ! of the velocity-point arrays is usually 0, not 1. This can only be set at\n",
    "                                ! compile time.```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5908ee1c-1411-4054-a72a-c5cf3ff14d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for non-symmetric \n",
    "# SYMMETRIC_MEMORY_ = False\n",
    "# see https://xgcm.readthedocs.io/en/latest/xgcm-examples/03_MOM6.html#xgcm-grid-definition\n",
    "# and https://xgcm.readthedocs.io/en/latest/grid_metrics.html#Using-metrics-with-xgcm\n",
    "grid = xgcm.Grid(static,\n",
    "                 coords={'X': {'center': 'xh', 'right': 'xq'},\n",
    "                         'Y': {'center': 'yh', 'right': 'yq'},},\n",
    "                         # 'Z': { 'inner': 'zl', 'outer': 'zi'}},\n",
    "                 metrics = {\n",
    "                        ('X',): ['dxt', 'dxCu', 'dxCv'], # X distances\n",
    "                        ('Y',): ['dyt', 'dyCu', 'dyCv'], # Y distances\n",
    "                        ('X', 'Y'): ['areacello', 'areacello_cu', 'areacello_cv', 'areacello_bu'] # Areas\n",
    "                        },\n",
    "                 periodic=['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b520d-c79b-4e9c-8912-9085a26f23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_marble = plt.imread('/g/data/ik11/grids/BlueMarble.tiff')\n",
    "blue_marble_extent = (-180, 180, -90, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc453f-7179-4203-ac73-17b5ed6077cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "access-om3.mom6.2d.mlotst.1mon.mean.1966.nc\n",
    "access-om3.mom6.2d.mlotst.1mon.max.1966.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f277935e-c042-4487-ac8d-b1473961c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f48f3da-5430-4df5-aa66-515a600ab01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datastores[1].search(variable='mlotst',\n",
    "                 frequency='1mon').df.head()['variable_cell_methods'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe8c78-0bdf-4a15-ba33-445d0ded5df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = dict()\n",
    "d = [ ds.search(variable='mlotst', frequency='1day', variable_cell_methods='.*time: mean.*') for ds in datastores ]\n",
    "d = [ ds.to_dask() for ds in d if ds ] # avoid .to_dask() for empty datasets\n",
    "data['mlotst'] = xr.concat(d, 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890bd11-d30f-445f-873c-07e9992e60c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date range\n",
    "trange = slice(cftime.DatetimeNoLeap(1970, 1, 1, 0, 0, 0, 0),\n",
    "               cftime.DatetimeNoLeap(1980, 1, 1, 0, 0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a9d2d-7a28-4828-95fc-7486bfc0b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLD_monthly_mean = data['mlotst']['mlotst'].sel(time=trange).groupby('time.month').mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9126f760-6550-4a2b-b5fb-edfd82d8692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small BUG: mean of monthly means is not mean of days in that month (eg Feb gets slightly more heavily weighted)\n",
    "MLD_JFM_mean = MLD_monthly_mean.sel(month=slice(1,3)).mean('month')\n",
    "MLD_JAS_mean = MLD_monthly_mean.sel(month=slice(7,9)).mean('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b1aba-0296-4acc-be1c-a8fbbdd0943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLD_JFM_mean.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00084e32-0e0b-4c3f-a3ab-89a1507e6e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLDmax = data['mlotst']['mlotst'].sel(time=trange).max('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d31a4-ed0e-4a27-85a3-2455fc53b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLDmax.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38545cff-aa93-460a-a662-6ac6369a958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to match Treguier et al 2023 fig 1 https://doi.org/10.5194/gmd-16-3849-2023\n",
    "dat = MLDmax.cf.assign_coords( { \"longitude\": static['geolon'],\n",
    "                                 \"latitude\": static['geolat'] })\n",
    "fname = thisdir+k+'_'+dat.attrs['long_name'].replace(' ', '_').replace('/', '_')+'.png'\n",
    "if os.path.isfile(fname):\n",
    "    print(f'   ---- skipping existing file {fname}')\n",
    "else:\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = plt.axes(projection=ccrs.Robinson(central_longitude=-100))\n",
    "    dat.plot.contourf(\n",
    "        ax=ax,\n",
    "        levels=51,\n",
    "        vmin=0,\n",
    "        vmax=500,\n",
    "        extend=\"max\",\n",
    "        # cmap=cm.cm.thermal,\n",
    "        cmap='viridis',\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        cbar_kwargs={\"label\": dat.attrs['units'], \"fraction\": 0.03, \"aspect\": 15, \"shrink\": 0.7},\n",
    "    )\n",
    "    \n",
    "    # Add blue marble land:\n",
    "    ax.imshow(\n",
    "        blue_marble, extent=blue_marble_extent, transform=ccrs.PlateCarree(), origin=\"upper\"\n",
    "    )\n",
    "    \n",
    "    plt.title(f\"Maximum Daily Mean {dat.attrs['long_name']}, {trange.start.strftime('%Y-%m-%d')} - {trange.stop.strftime('%Y-%m-%d')}\");\n",
    "    \n",
    "    # plt.savefig(fname, dpi=150)\n",
    "    # print(f'   saved {fname}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32634254-db0e-41d4-942f-4544316c4862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fields = [\n",
    "    'speed'\n",
    "]\n",
    "data = dict()\n",
    "for k in fields:\n",
    "    print(k)\n",
    "    # d = [ ds.search(variable=k).to_dataset_dict(xarray_combine_by_coords_kwargs=xarray_combine_by_coords_kwargs) for ds in datastores ]\n",
    "    try:\n",
    "        d = [ ds.search(variable=k, frequency='1day', variable_cell_methods='.*time: mean.*') for ds in datastores ]\n",
    "        d = [ ds.to_dask() for ds in d if ds ] # avoid .to_dask() for empty datasets\n",
    "    except ValueError:\n",
    "        # try:\n",
    "        #     d = [ ds.search(variable=k, frequency='1mon', variable_cell_methods='.*time: mean.*') for ds in datastores ]\n",
    "        #     d = [ ds.to_dask() for ds in d if ds ] # avoid .to_dask() for empty datasets\n",
    "        # except:\n",
    "        #     try:\n",
    "        #         d = [ ds.search(variable=k, variable_cell_methods='.*time: mean.*') for ds in datastores ]\n",
    "        #         d = [ ds.to_dask() for ds in d if ds ] # avoid .to_dask() for empty datasets\n",
    "        #     except:\n",
    "        #         try:\n",
    "        #             d = [ ds.search(variable=k, variable_cell_methods='.*time: point.*') for ds in datastores ]\n",
    "        #             d = [ ds.to_dask() for ds in d if ds ] # avoid .to_dask() for empty datasets\n",
    "        #         except:\n",
    "        #             try:\n",
    "        #                 d = [ ds.search(variable=k, variable_cell_methods='.*time: min.*') for ds in datastores ]\n",
    "        #                 d = [ ds.to_dask() for ds in d if ds ] # avoid .to_dask() for empty datasets\n",
    "        #             except:\n",
    "        #                 try:\n",
    "        #                     d = [ ds.search(variable=k, variable_cell_methods='.*time: max.*') for ds in datastores ]\n",
    "        #                     d = [ ds.to_dask() for ds in d if ds ] # avoid .to_dask() for empty datasets\n",
    "        #                 except:\n",
    "                            print(f'{k} failed')\n",
    "                            continue\n",
    "    if d:\n",
    "        data[k] = xr.concat(d, 'time')\n",
    "    else:\n",
    "        print(f'no data for {k}')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78601e-bea3-45a4-a3f6-d2141b1fb27a",
   "metadata": {},
   "source": [
    "### Make movie frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc97dec-ef70-4554-b684-ee379b24033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date range\n",
    "\n",
    "tstart = cftime.DatetimeNoLeap(1980, 1, 1, 0, 0, 0, 0)\n",
    "tend = cftime.DatetimeNoLeap(1981, 1, 1, 0, 0, 0, 0)\n",
    "timerange = slice(tstart, tend)\n",
    "print('tstart =', tstart)\n",
    "print('tend =', tend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4459f-b6f7-403d-84ed-9d3bef97099f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k, d in data.items():\n",
    "    print(k)\n",
    "    datall = d[k].sel(time=timerange)\n",
    "    # datall.load()\n",
    "    for t in datall.time.values:\n",
    "        dat = datall.sel(time=t).cf.assign_coords( { \"longitude\": static['geolon'],\n",
    "                                                    \"latitude\": static['geolat'] })\n",
    "        fname = thisdir+k+'_'+dat.attrs['long_name'].replace(' ', '_').replace('/', '_')+'_'+t.strftime('%Y-%m-%d')+'.png'\n",
    "        if os.path.isfile(fname):\n",
    "            print(f'   ---- skipping existing file {fname}')\n",
    "        else:\n",
    "            fig = plt.figure(figsize=(12, 6))\n",
    "            ax = plt.axes(projection=ccrs.Robinson(central_longitude=-100))\n",
    "            dat.plot.contourf(\n",
    "                ax=ax,\n",
    "                levels=33,\n",
    "                vmin=0,\n",
    "                vmax=1,\n",
    "                extend=\"max\",\n",
    "                cmap=cm.cm.thermal,\n",
    "                transform=ccrs.PlateCarree(),\n",
    "                cbar_kwargs={\"label\": dat.attrs['units'], \"fraction\": 0.03, \"aspect\": 15, \"shrink\": 0.7},\n",
    "            )\n",
    "            \n",
    "            # Add blue marble land:\n",
    "            ax.imshow(\n",
    "                blue_marble, extent=blue_marble_extent, transform=ccrs.PlateCarree(), origin=\"upper\"\n",
    "            )\n",
    "            \n",
    "            plt.title(dat.attrs['long_name']+' '+t.strftime('%Y-%m-%d'));\n",
    "\n",
    "            try:\n",
    "                plt.savefig(fname, dpi=150)\n",
    "                print(f'   saved {fname}')\n",
    "            except FileNotFoundError:\n",
    "                print(f'*** FileNotFoundError when saving {fname}')\n",
    "            # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dbf070-d000-487d-911d-2599c9e3476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! module load ffmpeg\n",
    "! ffmpeg -r 30 -pattern_type glob -i 'speed_Sea_Surface_Speed_*.png' -c:v libx264 -vf \"pad=trunc((iw+1)/2)*2:trunc((ih+1)/2)*2:0:0:white,crop=w=1506:h=692:x=219:y=92\" -preset veryslow -tune animation -crf 25 -pix_fmt yuv420p -r 30 Sea_Surface_Speed5.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff7bd34-9a50-41ed-a2f4-49a366d1a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "datall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62125ef3-f728-4b5f-88e7-4527942545bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "static['geolon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec77977f-7c8a-4ec4-b60c-d1560a963464",
   "metadata": {},
   "outputs": [],
   "source": [
    "datall.sel(time=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06354557-8d30-447e-9352-87a789b365dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed['speed'].isel(time=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6862b128-67ee-46d1-9115-9464b1d981b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.array.rechunk(datall, chunks='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d05e294-dac6-42f1-bed5-a1051a228a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "datall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c8bb7-95b4-4ab1-b7c4-2774a8267b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "datall.cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a50665e-de17-4647-b88e-b3ce721b2d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datall.cf.assign_coords(\n",
    "        { \"longitude\": static['geolon'],\n",
    "         \"latitude\": static['geolat'] }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122a8e0f-bbd2-4271-bf13-ca60260374fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed.speed.isel(time=-1).cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa90ffae-eb15-4525-9bbe-91d4eea7ee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = plt.axes(projection=ccrs.Robinson(central_longitude=-100))\n",
    "\n",
    "speed.speed.isel(time=-1).cf.assign_coords({ \"longitude\": static['geolon'],\n",
    "                                             \"latitude\": static['geolat'] }\n",
    "                                        ).plot.contourf(\n",
    "    ax=ax,\n",
    "    # x=\"longitude\",\n",
    "    # y=\"latitude\",\n",
    "    levels=33,\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    extend=\"max\",\n",
    "    cmap=cm.cm.thermal,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    cbar_kwargs={\"fraction\": 0.03, \"aspect\": 15, \"shrink\": 0.7},\n",
    ")\n",
    "\n",
    "# Add blue marble land:\n",
    "ax.imshow(\n",
    "    blue_marble, extent=blue_marble_extent, transform=ccrs.PlateCarree(), origin=\"upper\"\n",
    ")\n",
    "\n",
    "plt.title(speed.speed.attrs['long_name']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c089b2aa-4e9b-4dc1-bee6-4740a143140e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# OLD BELOW"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fba33a8-e5c2-4277-a600-e6e3527d11ce",
   "metadata": {},
   "source": [
    "datastore.search(path='.*access-om3\\.mom6\\.h\\.native.*',\n",
    "                          frequency='1mon',\n",
    "                          variable_cell_methods='.*time: mean.*'\n",
    "                         ).to_dask(xarray_combine_by_coords_kwargs=xarray_combine_by_coords_kwargs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a640125-4270-4c6a-976e-da80c4aa59c2",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "datastore.search(path=ncpath+'.*',\n",
    "                          frequency='1mon',\n",
    "                          variable_cell_methods='.*time: mean.*'\n",
    "                         ).to_dataset_dict(xarray_combine_by_coords_kwargs=xarray_combine_by_coords_kwargs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7f7912d-ee76-42ee-9511-a223a22e9203",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "datastore.search(variable='KE', frequency='1mon').df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4112ebcc-ab62-455f-9d17-e11906fd1d14",
   "metadata": {},
   "source": [
    "datastores[0].search(variable=k).to_dask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7b8ca1-bf2c-4cf7-9d8d-35ae24f2e657",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fields = ['tosga', 'thetaoga', 'tos', 'sosga', 'soga', 'sos', 'SSH']#, 'KE', 'sss_global', 'volo', 'masso',]\n",
    "fields = [ # from ncdump -h ctrl_run_25km_0.5/archive/output009/access-om3.mom6.scalar.1day.snap.1962.nc | grep double\n",
    "    'soga',\n",
    "    'thetaoga',\n",
    "    'tosga',\n",
    "    'sosga',\n",
    "    'total_salt_Flux_Added',\n",
    "    'total_salt_Flux_In',\n",
    "    'total_salt_flux',\n",
    "    'net_fresh_water_global_adjustment',\n",
    "    'salt_flux_global_restoring_adjustment',\n",
    "    'total_wfo',\n",
    "    'total_evs',\n",
    "    'total_fsitherm',\n",
    "    'total_precip',\n",
    "    'total_prsn',\n",
    "    'total_lprec',\n",
    "    'total_ficeberg',\n",
    "    'total_friver',\n",
    "    'total_net_massout',\n",
    "    'total_net_massin',\n",
    "]\n",
    "data = dict()\n",
    "for k in fields:\n",
    "    print(k)\n",
    "    # d = [ ds.search(variable=k).to_dataset_dict(xarray_combine_by_coords_kwargs=xarray_combine_by_coords_kwargs) for ds in datastores ]\n",
    "    try:\n",
    "        d = [ ds.search(variable=k) for ds in datastores ]\n",
    "        d = [ ds.to_dask() for ds in d if ds ] # avoid .to_dask() for empty datasets\n",
    "    except ValueError:\n",
    "        try:\n",
    "            d = [ ds.search(variable=k, frequency='1mon', variable_cell_methods='.*time: mean.*') for ds in datastores ]\n",
    "            d = [ ds.to_dask() for ds in d if ds ] # avoid .to_dask() for empty datasets\n",
    "        except:\n",
    "            try:\n",
    "                d = [ ds.search(variable=k, variable_cell_methods='.*time: mean.*') for ds in datastores ]\n",
    "                d = [ ds.to_dask() for ds in d if ds ] # avoid .to_dask() for empty datasets\n",
    "            except:\n",
    "                try:\n",
    "                    d = [ ds.search(variable=k, variable_cell_methods='.*time: point.*') for ds in datastores ]\n",
    "                    d = [ ds.to_dask() for ds in d if ds ] # avoid .to_dask() for empty datasets\n",
    "                except:\n",
    "                    try:\n",
    "                        d = [ ds.search(variable=k, variable_cell_methods='.*time: min.*') for ds in datastores ]\n",
    "                        d = [ ds.to_dask() for ds in d if ds ] # avoid .to_dask() for empty datasets\n",
    "                    except:\n",
    "                        try:\n",
    "                            d = [ ds.search(variable=k, variable_cell_methods='.*time: max.*') for ds in datastores ]\n",
    "                            d = [ ds.to_dask() for ds in d if ds ] # avoid .to_dask() for empty datasets\n",
    "                        except:\n",
    "                            print(f'{k} failed')\n",
    "                            continue\n",
    "    if d:\n",
    "        data[k] = xr.concat(d, 'time')\n",
    "    else:\n",
    "        print(f'no data for {k}')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a301c-f200-416a-b092-d7cb69ee8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad19d277-7b17-41e8-99e5-37422abeb6e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k, d in data.items():\n",
    "    print(k)\n",
    "    dat = d[k]\n",
    "    fname = thisdir+k+'_'+dat.attrs['long_name'].replace(' ', '_')+'.png'\n",
    "    if os.path.isfile(fname):\n",
    "        print(f'---- skipping existing file {fname}')\n",
    "    else:\n",
    "        if 'depth' in dat.cf.coords: # https://xgcm.readthedocs.io/en/latest/grid_metrics.html?highlight=average#Grid-aware-(weighted)-average\n",
    "            dat = grid.average(dat, ['X', 'Y', 'Z'])\n",
    "        elif 'longitude' in dat.cf.coords: # https://xgcm.readthedocs.io/en/latest/grid_metrics.html?highlight=average#Grid-aware-(weighted)-average\n",
    "            dat = grid.average(dat, ['X', 'Y'])\n",
    "        dat.load()\n",
    "        if int((dat.time[1]-dat.time[0]).values/1e9/60/60/24) == 1:\n",
    "            label = 'daily'\n",
    "        else:\n",
    "            label = 'monthly mean' # possible BUG: plausible guess\n",
    "        plt.figure(figsize=(10,5))\n",
    "        dat.plot(label=label)\n",
    "        dat.cf.resample(time='1YE').mean('time').plot(label='annual mean')\n",
    "        # dat.cf.rolling(time=12, center=True).mean('time').plot()\n",
    "        # dat.cf.rolling(time='1YE', center=True).mean('time').plot()\n",
    "        plt.title(k+': '+dat.attrs['long_name'])#+' ['+dat.attrs['units']+']')\n",
    "        plt.legend()\n",
    "        try:\n",
    "            plt.savefig(fname, dpi=150)\n",
    "            print(f'saved {fname}')\n",
    "        except FileNotFoundError:\n",
    "            print(f'*** FileNotFoundError when saving {fname}')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a4094-938c-4e02-a2f1-11e91c457eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.attrs['long_name'].replace(' ', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2492ef-2445-42b8-a8c4-9f406bcf02cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# OLDER BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c1b7a0-77ff-491d-9529-431ff91d6d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fields_mean = ['tosga', 'thetaoga', 'tos', 'sosga', 'soga', 'sos', 'sss_global', 'SSH', 'volo', 'masso',]# 'KE']\n",
    "data_mean = { k: datastore.search(variable=k, \n",
    "                                  # frequency='1mon', \n",
    "                                  # variable_cell_methods='.*time: mean.*'\n",
    "                                 ).to_dataset_dict(\n",
    "    xarray_combine_by_coords_kwargs=xarray_combine_by_coords_kwargs) for k in fields_mean }\n",
    "data_mean = { k: list(v.values())[0] for k, v in data_mean.items() if v } # drop any empty datasets\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135b615-fd4e-41b2-a140-001ca62367c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_mean = ['thetaoga', 'tos', 'soga', 'sos', 'sss_global', 'SSH', 'volo', 'masso',]# 'KE']\n",
    "data_mean = { k: datastore.search(variable=k, \n",
    "                                  frequency='1mon', \n",
    "                                  # variable_cell_methods='.*time: mean.*'\n",
    "                                 ).to_dataset_dict(\n",
    "    xarray_combine_by_coords_kwargs=xarray_combine_by_coords_kwargs) for k in fields_mean }\n",
    "data_mean = { k: list(v.values())[0] for k, v in data_mean.items() if v } # drop any empty datasets\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3637f-5208-49e9-8e0e-b6f26b906fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_min = [ 'SSH_min', 'mlotst_min','uh', 'vh' ]\n",
    "data_min = { k: datastore.search(variable=k, \n",
    "                                 frequency='1mon', \n",
    "                                 variable_cell_methods='.*time: min.*'\n",
    "                                ).to_dataset_dict(\n",
    "    xarray_combine_by_coords_kwargs=xarray_combine_by_coords_kwargs) for k in fields_min }\n",
    "data_min = { k: list(v.values())[0] for k, v in data_min.items() if v } # drop any empty datasets\n",
    "data_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc4ddf4-dc44-46af-84d8-37497bc68ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_max = [ 'SSH_max', 'mlotst_max', 'uh', 'vh' ]\n",
    "data_max = { k: datastore.search(\n",
    "    variable=k, \n",
    "    frequency='1mon', \n",
    "    variable_cell_methods='.*time: max.*'\n",
    ").to_dataset_dict(\n",
    "    xarray_combine_by_coords_kwargs=xarray_combine_by_coords_kwargs) for k in fields_max }\n",
    "data_max = { k: list(v.values())[0] for k, v in data_max.items() if v } # drop any empty datasets\n",
    "data_max"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce2dfa4b-e424-409d-959a-dfe53213ead5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "data['thetaoga'].pint.quantify().pint.to('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f0d9f-4e02-4abe-ba7e-c0c02db4bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, d in data_mean.items():\n",
    "    dat = d[k]\n",
    "    if 'depth' in dat.cf.coords: # https://xgcm.readthedocs.io/en/latest/grid_metrics.html?highlight=average#Grid-aware-(weighted)-average\n",
    "        dat = grid.average(dat, ['X', 'Y', 'Z'])\n",
    "    elif 'longitude' in dat.cf.coords: # https://xgcm.readthedocs.io/en/latest/grid_metrics.html?highlight=average#Grid-aware-(weighted)-average\n",
    "        dat = grid.average(dat, ['X', 'Y'])\n",
    "    dat.load()\n",
    "    if int((dat.time[1]-dat.time[0]).values/1e9/60/60/24) == 1:\n",
    "        label = 'daily'\n",
    "    else:\n",
    "        label = 'monthly mean' # BUG: wild guess\n",
    "    plt.figure(figsize=(10,5))\n",
    "    dat.plot(label=label)\n",
    "    dat.cf.resample(time='1YE').mean('time').plot(label='annual mean')\n",
    "    # dat.cf.rolling(time=12, center=True).mean('time').plot()\n",
    "    # dat.cf.rolling(time='1YE', center=True).mean('time').plot()\n",
    "    plt.title(k)\n",
    "    plt.legend()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbb4a19-8392-4688-95c2-da3f0fd8deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, d in data_min.items():\n",
    "    dat = d[k]\n",
    "    if 'depth' in dat.cf.coords: # https://xgcm.readthedocs.io/en/latest/grid_metrics.html?highlight=average#Grid-aware-(weighted)-average\n",
    "        dat = dat.cf.min(dim=['latitude', 'longitude', 'depth'])\n",
    "    elif 'longitude' in dat.cf.coords: # https://xgcm.readthedocs.io/en/latest/grid_metrics.html?highlight=average#Grid-aware-(weighted)-average\n",
    "        dat = dat.cf.min(dim=['latitude', 'longitude'])\n",
    "    dat.load()\n",
    "    plt.figure(figsize=(10,5))\n",
    "    dat.plot()\n",
    "    dat.cf.rolling(time=12, center=True).mean('time').plot()\n",
    "    plt.title(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a735739-661f-4af0-9c07-0b0771163f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, d in data_max.items():\n",
    "    dat = d[k]\n",
    "    if 'depth' in dat.cf.coords: # https://xgcm.readthedocs.io/en/latest/grid_metrics.html?highlight=average#Grid-aware-(weighted)-average\n",
    "        dat = dat.cf.max(dim=['latitude', 'longitude', 'depth'])\n",
    "    elif 'longitude' in dat.cf.coords: # https://xgcm.readthedocs.io/en/latest/grid_metrics.html?highlight=average#Grid-aware-(weighted)-average\n",
    "        dat = dat.cf.max(dim=['latitude', 'longitude'])\n",
    "    dat.load()\n",
    "    plt.figure(figsize=(10,5))\n",
    "    dat.plot()\n",
    "    dat.cf.rolling(time=12, center=True).mean('time').plot()\n",
    "    plt.title(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c1dbbb-5931-49a9-aee1-308706d4f43e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
